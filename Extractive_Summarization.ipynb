{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Automatic_Summarization_extractive.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CWYh2xgKQjdl",
        "colab_type": "text"
      },
      "source": [
        "### Personalized Text Rank algorithm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YKwnH2-w_96E",
        "colab_type": "text"
      },
      "source": [
        "Get article"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AKmY9XH6_ZUE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize \n",
        "def get_sentences(article):\n",
        "  extracts=sent_tokenize(article)\n",
        "  sentences=[]\n",
        "  for extract in extracts:\n",
        "    #print(extract)\n",
        "    clean_sentence=extract.replace(\"[^a-zA-Z0-9]\",\" \")   ## Removing special characters\n",
        "    #print(clean_sentence)\n",
        "    obtained=word_tokenize(clean_sentence) \n",
        "    #print(obtained)\n",
        "    sentences.append(obtained)\n",
        "\n",
        "  return sentences\n",
        "\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C5oAXRHKL_-1",
        "colab_type": "text"
      },
      "source": [
        "Get similarity"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "54n8vH7rIDpk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "from nltk.cluster.util import cosine_distance\n",
        "def get_similarity(sent_1,sent_2,stop_words):\n",
        "  \n",
        "  sent_1=[w.lower() for w in sent_1]\n",
        "  sent_2=[w.lower() for w in sent_2]\n",
        "\n",
        "  total=list(set(sent_1+sent_2)) ## Removing duplicate words in total set\n",
        "\n",
        "  vec_1= [0] * len(total)\n",
        "  vec_2= [0] * len(total)\n",
        "\n",
        "\n",
        "  ## Count Vectorization of two sentences\n",
        "  for w in sent_1:\n",
        "    if w not in stop_words:\n",
        "      vec_1[total.index(w)]+=1\n",
        "\n",
        "  for w in sent_2:\n",
        "    if w not in stop_words:\n",
        "      vec_2[total.index(w)]+=1\n",
        "\n",
        "\n",
        "  return 1-cosine_distance(vec_1,vec_2)\n",
        "\n",
        "\n",
        "  \n",
        "    \n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sleiTeV8MC6l",
        "colab_type": "text"
      },
      "source": [
        " Create matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6HFT6yEmL_cp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.corpus import stopwords\n",
        "import numpy as np\n",
        "def build_matrix(sentences):\n",
        "  stop_words = stopwords.words('english')\n",
        "\n",
        "  sim_matrix=np.zeros((len(sentences),len(sentences)))\n",
        "  ## Adjacency matrix\n",
        "\n",
        "  for id1 in range(len(sentences)):\n",
        "    for id2 in range(len(sentences)):\n",
        "      if id1==id2:  #escaping diagonal elements\n",
        "        continue\n",
        "      else:\n",
        "        sim_matrix[id1][id2]=get_similarity(sentences[id1],sentences[id2],stop_words)\n",
        "\n",
        "  return sim_matrix\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ICXvULefNca_",
        "colab_type": "text"
      },
      "source": [
        "Page Rank"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xzxfvz-wNcD_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def pagerank(text, eps=0.000001, d=0.85):\n",
        "    score_mat = np.ones(len(text)) / len(text)\n",
        "    delta=1\n",
        "    ### iterative approach\n",
        "    while delta>eps:\n",
        "        score_mat_new = np.ones(len(text)) * (1 - d) / len(text) + d * text.T.dot(score_mat)\n",
        "        delta = abs(score_mat_new - score_mat).sum()\n",
        "        score_mat = score_mat_new\n",
        "\n",
        "    return score_mat_new"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D4tVgHZcO1_z",
        "colab_type": "text"
      },
      "source": [
        "Summarizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q9e9StjFOyXg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def summarizer(article,req=3):\n",
        "  summarized=[]\n",
        "\n",
        "  sentence=get_sentences(article)\n",
        "\n",
        "  sim_matrix=build_matrix(sentence)\n",
        "\n",
        "  score=pagerank(sim_matrix)\n",
        "\n",
        "  ranked_sentence = sorted(((score[i],s) for i,s in enumerate(sentence)), reverse=True)\n",
        "  #print(ranked_sentence[2])\n",
        "  \n",
        "  for i in range(req):\n",
        "      #print(ranked_sentence[i][1])\n",
        "      summarized.append(\" \".join(ranked_sentence[i][1]))\n",
        "\n",
        "  return summarized\n",
        "\n"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y7o6Ej1hQpdg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bcdbba26-c417-4b43-d359-b9f5aa52eee8"
      },
      "source": [
        "Article='Compatibility of systems of linear constraints over the set of natural numbers. Criteria of compatibility of a system of linear Diophantine equations, strict inequations, and nonstrict inequations are considered. Upper bounds for components of a minimal set of solutions and algorithms of construction of minimal generating sets of solutions for all types of systems are given. These criteria and the corresponding algorithms for constructing a minimal supporting set of solutions can be used in solving all the considered types systems and systems of mixed types.'\n",
        "len(Article)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "564"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zkYWa4t5RAl2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "e5d941dd-c671-42b9-f01c-2f1403e9bcfc"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "Summary=summarizer(Article)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "['These', 'criteria', 'and', 'the', 'corresponding', 'algorithms', 'for', 'constructing', 'a', 'minimal', 'supporting', 'set', 'of', 'solutions', 'can', 'be', 'used', 'in', 'solving', 'all', 'the', 'considered', 'types', 'systems', 'and', 'systems', 'of', 'mixed', 'types', '.']\n",
            "['Upper', 'bounds', 'for', 'components', 'of', 'a', 'minimal', 'set', 'of', 'solutions', 'and', 'algorithms', 'of', 'construction', 'of', 'minimal', 'generating', 'sets', 'of', 'solutions', 'for', 'all', 'types', 'of', 'systems', 'are', 'given', '.']\n",
            "['Compatibility', 'of', 'systems', 'of', 'linear', 'constraints', 'over', 'the', 'set', 'of', 'natural', 'numbers', '.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3O-RG9iVSzCd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "122936aa-6730-4de4-c1ce-87308c8d6745"
      },
      "source": [
        "print(Summary)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['These criteria and the corresponding algorithms for constructing a minimal supporting set of solutions can be used in solving all the considered types systems and systems of mixed types .', 'Upper bounds for components of a minimal set of solutions and algorithms of construction of minimal generating sets of solutions for all types of systems are given .', 'Compatibility of systems of linear constraints over the set of natural numbers .']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GNW6bXVxZIeu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "outputId": "e500d852-0efe-4869-c384-e49459e38bcd"
      },
      "source": [
        "!pip3 install pytextrank "
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pytextrank\n",
            "  Downloading https://files.pythonhosted.org/packages/41/87/1885457ce4389edd7c8454fd9ca3285e324e2d80fccec7edbd98c3e27ff0/pytextrank-2.0.2-py3-none-any.whl\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.6/dist-packages (from pytextrank) (2.4)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.6/dist-packages (from pytextrank) (2.2.4)\n",
            "Requirement already satisfied: coverage in /usr/local/lib/python3.6/dist-packages (from pytextrank) (3.7.1)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.6/dist-packages (from pytextrank) (0.10.1)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx->pytextrank) (4.4.2)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy->pytextrank) (1.18.5)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy->pytextrank) (2.0.3)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy->pytextrank) (1.1.3)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy->pytextrank) (3.0.2)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy->pytextrank) (1.0.2)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy->pytextrank) (4.41.1)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy->pytextrank) (1.0.0)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy->pytextrank) (7.4.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy->pytextrank) (0.4.1)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy->pytextrank) (1.0.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy->pytextrank) (49.2.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy->pytextrank) (2.23.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy->pytextrank) (0.7.1)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy->pytextrank) (1.7.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy->pytextrank) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy->pytextrank) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy->pytextrank) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy->pytextrank) (2020.6.20)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy->pytextrank) (3.1.0)\n",
            "Installing collected packages: pytextrank\n",
            "Successfully installed pytextrank-2.0.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "025szUsyS-rW",
        "colab_type": "text"
      },
      "source": [
        "### Using Spacy and PytextRank"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fMiBUdCMTEUe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "495c3c75-738e-4fb2-eafd-e55b9fc13232"
      },
      "source": [
        "import spacy\n",
        "import pytextrank\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# add PyTextRank to the spaCy pipeline\n",
        "tr = pytextrank.TextRank()\n",
        "nlp.add_pipe(tr.PipelineComponent, name=\"textrank\", last=True)\n",
        "\n",
        "doc = nlp(Article)\n",
        "\n",
        "# examine the top-ranked phrases in the document\n",
        "for p in doc._.phrases[0:10]:\n",
        "    \n",
        "    print(p.chunks)\n"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[minimal generating sets]\n",
            "[systems, systems, systems, a system]\n",
            "[solutions, solutions, solutions]\n",
            "[mixed types]\n",
            "[strict inequations]\n",
            "[nonstrict inequations]\n",
            "[Diophantine equations]\n",
            "[a minimal supporting set]\n",
            "[linear constraints]\n",
            "[a minimal set]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}