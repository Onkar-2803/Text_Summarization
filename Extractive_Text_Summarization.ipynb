{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Extractive Text Summarization.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPBGy21Ew0IBXCP/F3mwIri",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Onkar-2803/Text_Summarization/blob/main/Extractive_Text_Summarization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RQWSBLtowVBQ"
      },
      "source": [
        "from nltk.tokenize import sent_tokenize, word_tokenize \n",
        "def get_sentences(article):\n",
        "  extracts=sent_tokenize(article)\n",
        "  sentences=[]\n",
        "  for extract in extracts:\n",
        "    #print(extract)\n",
        "    clean_sentence=extract.replace(\"[^a-zA-Z0-9]\",\" \")   ## Removing special characters\n",
        "    #print(clean_sentence)\n",
        "    obtained=word_tokenize(clean_sentence) \n",
        "    #print(obtained)\n",
        "    sentences.append(obtained)\n",
        "\n",
        "  return sentences"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "38OvPRwEwg-a"
      },
      "source": [
        "from nltk.cluster.util import cosine_distance\n",
        "def get_similarity(sent_1,sent_2,stop_words):\n",
        "  \n",
        "  sent_1=[w.lower() for w in sent_1]\n",
        "  sent_2=[w.lower() for w in sent_2]\n",
        "\n",
        "  total=list(set(sent_1+sent_2)) ## Removing duplicate words in total set\n",
        "\n",
        "  vec_1= [0] * len(total)\n",
        "  vec_2= [0] * len(total)\n",
        "\n",
        "\n",
        "  ## Count Vectorization of two sentences\n",
        "  for w in sent_1:\n",
        "    if w not in stop_words:\n",
        "      vec_1[total.index(w)]+=1\n",
        "\n",
        "  for w in sent_2:\n",
        "    if w not in stop_words:\n",
        "      vec_2[total.index(w)]+=1\n",
        "\n",
        "\n",
        "  return 1-cosine_distance(vec_1,vec_2)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rqZAk7hWwiZM"
      },
      "source": [
        "from nltk.corpus import stopwords\n",
        "import numpy as np\n",
        "def build_matrix(sentences):\n",
        "  stop_words = stopwords.words('english')\n",
        "\n",
        "  sim_matrix=np.zeros((len(sentences),len(sentences)))\n",
        "  ## Adjacency matrix\n",
        "\n",
        "  for id1 in range(len(sentences)):\n",
        "    for id2 in range(len(sentences)):\n",
        "      if id1==id2:  #escaping diagonal elements\n",
        "        continue\n",
        "      else:\n",
        "        sim_matrix[id1][id2]=get_similarity(sentences[id1],sentences[id2],stop_words)\n",
        "\n",
        "  return sim_matrix"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vgypLxwhwjop"
      },
      "source": [
        "def pagerank(text, eps=0.000001, d=0.85):\n",
        "    score_mat = np.ones(len(text)) / len(text)\n",
        "    delta=1\n",
        "    ### iterative approach\n",
        "    while delta>eps:\n",
        "        score_mat_new = np.ones(len(text)) * (1 - d) / len(text) + d * text.T.dot(score_mat)\n",
        "        delta = abs(score_mat_new - score_mat).sum()\n",
        "        score_mat = score_mat_new\n",
        "\n",
        "    return score_mat_new"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pTccLi5Qwk0l"
      },
      "source": [
        "def summarizer(article,req=3):\n",
        "  summarized=[]\n",
        "\n",
        "  sentence=get_sentences(article)\n",
        "\n",
        "  sim_matrix=build_matrix(sentence)\n",
        "\n",
        "  score=pagerank(sim_matrix)\n",
        "\n",
        "  ranked_sentence = sorted(((score[i],s) for i,s in enumerate(sentence)), reverse=True)\n",
        "  #print(ranked_sentence[2])\n",
        "  \n",
        "  for i in range(req):\n",
        "      #print(ranked_sentence[i][1])\n",
        "      summarized.append(\" \".join(ranked_sentence[i][1]))\n",
        "\n",
        "  return summarized"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ypOizgBXwnIx",
        "outputId": "50a227be-e42e-4fb3-9b77-5d7eaeb41d2b"
      },
      "source": [
        "Article='Compatibility of systems of linear constraints over the set of natural numbers. Criteria of compatibility of a system of linear Diophantine equations, strict inequations, and nonstrict inequations are considered. Upper bounds for components of a minimal set of solutions and algorithms of construction of minimal generating sets of solutions for all types of systems are given. These criteria and the corresponding algorithms for constructing a minimal supporting set of solutions can be used in solving all the considered types systems and systems of mixed types.'\n",
        "len(Article)\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "564"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VPFh7QWOwo-R",
        "outputId": "add09fc3-f90e-460f-fe3a-2ffc2a90dab5"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "Summary=summarizer(Article)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fi_99h--wq3C",
        "outputId": "ffdc587b-fe22-4a34-e5b5-6b78d0f39389"
      },
      "source": [
        "print(Summary)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['These criteria and the corresponding algorithms for constructing a minimal supporting set of solutions can be used in solving all the considered types systems and systems of mixed types .', 'Upper bounds for components of a minimal set of solutions and algorithms of construction of minimal generating sets of solutions for all types of systems are given .', 'Compatibility of systems of linear constraints over the set of natural numbers .']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p-ybNuEjwt3F"
      },
      "source": [
        "Article_2 = '''The police are entrusted with the duty of maintaining the peace and harmony of a society. Moreover, they also have the right to arrest and control people who do not follow the law. As a result, they are important as they protect our society.\n",
        "Enforcing the laws of the land, the police also has the right to punish people who do not obey the law. Consequently, we, as citizens, feel safe and do not worry much about our lives and property.'''"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EC3-zCnWxKgH"
      },
      "source": [
        "Summary=summarizer(Article_2)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "folT-1zoxMvy",
        "outputId": "1cd7c338-6459-498b-8dbf-44c661d7fa81"
      },
      "source": [
        "print(Summary)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Enforcing the laws of the land , the police also has the right to punish people who do not obey the law .', 'Moreover , they also have the right to arrest and control people who do not follow the law .', 'As a result , they are important as they protect our society .']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_2vN2MnNxN8e"
      },
      "source": [
        ""
      ],
      "execution_count": 14,
      "outputs": []
    }
  ]
}